"""Strategies for testing."""
# Part of this is written by the  `hypothesis.extra.ghostwriter` module.
# pyright: strict
import logging
from typing import Callable
from typing import cast
from typing import ChainMap
from typing import List
from typing import Optional
from typing import Sequence
from typing import Set
from typing import Tuple
from typing import Type
from typing import TypeVar

from hypothesis import assume as assume
from hypothesis import note as note
from hypothesis import strategies as st

from .token_types import _SymbolType  # pyright: ignore [reportPrivateUsage]
from .token_types import ClosingDelim
from .token_types import DelimPair
from .token_types import OpeningDelim
from .token_types import Operator
from .token_types import RPNToken
from .token_types import Token
from .util import RPNNode
from .util import sanity_check_operators

logger = logging.getLogger(__name__)

BLACKLIST_CATEGORIES = ("C", "Z")
MAX_ARGS = 10

characters_strategy: st.SearchStrategy[str] = st.characters(
    blacklist_categories=BLACKLIST_CATEGORIES
)
non_empty_string_strategy: st.SearchStrategy[str] = st.text(
    alphabet=characters_strategy, min_size=1
)

delim_pair_strategy: st.SearchStrategy[DelimPair] = st.builds(
    DelimPair,
    opening=non_empty_string_strategy,
    closing=non_empty_string_strategy,
)

delim_pairs_strategy: st.SearchStrategy[Sequence[DelimPair]] = st.one_of(
    st.lists(st.builds(DelimPair)),
    st.sets(st.builds(DelimPair, delim_pair_strategy)),
    st.frozensets(st.builds(DelimPair, delim_pair_strategy)),
    st.dictionaries(
        keys=st.builds(DelimPair, delim_pair_strategy),
        values=st.builds(DelimPair, delim_pair_strategy),
    ),
    st.dictionaries(
        keys=st.builds(DelimPair, delim_pair_strategy), values=st.none()
    ).map(
        dict.keys  # type: ignore[arg-type]
    ),
    st.dictionaries(
        keys=st.integers(), values=st.builds(DelimPair, delim_pair_strategy)
    ).map(
        dict.values  # type: ignore[arg-type]
    ),
    st.iterables(st.builds(DelimPair, delim_pair_strategy)),
    st.dictionaries(
        keys=st.builds(DelimPair, delim_pair_strategy),
        values=st.builds(DelimPair, delim_pair_strategy),
    ).map(
        ChainMap  # type: ignore[arg-type]
    ),
)


# The following strategies are based upon the code generated by the `hypothesis.extra.ghostwriter` module
def operator_strategy_from_symbol_strategy(
    symbol_strategy: st.SearchStrategy[_SymbolType],
) -> st.SearchStrategy[Operator[_SymbolType]]:
    """Create a strategy to create an Operator[_SymbolType] by providing a strategy for _SymbolType.

    Args:
        symbol_strategy (SearchStrategy[_SymbolType]): Strategy to create a symbol value for the operator.

    Returns:
        SearchStrategy[Operator[_SymbolType]]: Strategy creating an Operator using _SymbolType as it's value.
    """
    operator_unary_strategy: st.SearchStrategy[Operator[_SymbolType]] = st.builds(
        Operator[_SymbolType],
        value=symbol_strategy,
        associativity=st.sampled_from(
            [
                "none",
                # "right", associativity is only defined for binary operators
                # "left" associativity is only defined for binary operators
            ]
        ),
        name=st.one_of(st.none(), st.one_of(st.none(), st.text())),
        precedence=st.one_of(st.just(0), st.integers()),
        unary=st.one_of(
            st.just(True),  # only unary operators
        ),
        unary_position=st.one_of(
            st.sampled_from(["postfix", "prefix"]),
        ),
    )
    operator_both_strategy: st.SearchStrategy[Operator[_SymbolType]] = st.builds(
        Operator[_SymbolType],
        value=symbol_strategy,
        associativity=st.one_of(
            st.just("left"),
            st.sampled_from(
                [
                    # "none", # both operators should be associative
                    "right",
                    "left",
                ]
            ),
        ),
        name=st.one_of(st.none(), st.one_of(st.none(), st.text())),
        precedence=st.one_of(st.just(0), st.integers()),
        unary=st.one_of(
            st.just("both"),  # only both operators
        ),
        unary_position=st.one_of(
            st.sampled_from(["postfix", "prefix"]),
        ),
    )
    operator_binary_strategy: st.SearchStrategy[Operator[_SymbolType]] = st.builds(
        Operator[_SymbolType],
        value=symbol_strategy,
        associativity=st.sampled_from(
            [
                # "none", # binary operators should be associative
                "right",
                "left",
            ]
        ),
        name=st.one_of(st.none(), st.one_of(st.none(), st.text())),
        precedence=st.one_of(st.just(0), st.integers()),
        unary=st.one_of(
            st.just(False),  # only binary operators
        ),
        unary_position=st.one_of(st.none()),
    )
    operator_element_strategy: st.SearchStrategy[Operator[_SymbolType]] = st.one_of(
        operator_unary_strategy,
        operator_binary_strategy,
        operator_both_strategy,
    )
    return operator_element_strategy


non_empty_token_strategy: st.SearchStrategy[Token] = st.builds(
    cast("Callable[[str],Token]", Token), non_empty_string_strategy
)

non_empty_token_operator_strategy = operator_strategy_from_symbol_strategy(
    symbol_strategy=non_empty_token_strategy
)

st.register_type_strategy(Operator, non_empty_token_operator_strategy)


def operator_from_symbol_type_strategy(
    symbol_type: Type[_SymbolType],
) -> st.SearchStrategy[Operator[_SymbolType]]:
    """Create a strategy to create an Operator[_SymbolType] by providing an explicit type for _SymbolType.

    Args:
        symbol_strategy (Type[_SymbolType]): explicit type for the symbol value of the operator.

    Returns:
        SearchStrategy[Operator[_SymbolType]]: Strategy creating an Operator using _SymbolType as it's value.
    """
    symbol_strategy: st.SearchStrategy[_SymbolType] = st.from_type(symbol_type)
    return operator_strategy_from_symbol_strategy(symbol_strategy=symbol_strategy)


st.register_type_strategy(Operator[Token], operator_from_symbol_type_strategy(Token))


def operators_strategy_from_symbol_strategy(
    symbol_strategy: st.SearchStrategy[_SymbolType], min_size: int = 1
) -> st.SearchStrategy[Sequence[Operator[_SymbolType]]]:
    """Create a strategy to create an Sequence of Operator[_SymbolType] by providing a strategy for _SymbolType.

    Args:
        symbol_strategy (SearchStrategy[_SymbolType]): Strategy to create a symbol value for the operator.
        min_size (int, optional): Minimal size of the sequence. Defaults to 1.

    Returns:
        SearchStrategy[Operator[_SymbolType]]: Strategy creating an Operator using _SymbolType as it's value.
    """
    operator_element_strategy = operator_strategy_from_symbol_strategy(
        symbol_strategy=symbol_strategy
    )

    return st.one_of(
        st.lists(
            operator_element_strategy,
            min_size=min_size,
        ),
        st.sets(
            operator_element_strategy,
            min_size=min_size,
        ),
        st.frozensets(
            operator_element_strategy,
            min_size=min_size,
        ),
        st.dictionaries(
            keys=operator_element_strategy,
            values=operator_element_strategy,
            min_size=min_size,
        ),
        st.dictionaries(
            keys=operator_element_strategy,
            values=st.none(),
            min_size=min_size,
        ).map(
            dict.keys  # type: ignore[arg-type]
        ),
        st.dictionaries(
            keys=st.integers(),
            values=operator_element_strategy,
            min_size=min_size,
        ).map(
            dict.values  # type: ignore[arg-type]
        ),
        st.iterables(
            operator_element_strategy,
            min_size=min_size,
        ),
        st.dictionaries(
            keys=operator_element_strategy,
            values=operator_element_strategy,
            min_size=min_size,
        ).map(
            ChainMap  # type: ignore[arg-type]
        ),
    )


def _extract_value_from_ops(
    ops: Sequence[Operator[_SymbolType]],
) -> List[_SymbolType]:
    return [op.value for op in ops]


ops_strategy: st.SearchStrategy[
    Sequence[Operator[Token]]
] = operators_strategy_from_symbol_strategy(symbol_strategy=non_empty_token_strategy)

_T = TypeVar("_T")


@st.composite
def alternating_strategy(
    draw: "st.DrawFn",
    a: Sequence[_T],
    b: Sequence[_T],
    *,
    min_size: int = 1,
    max_size: Optional[int] = 10,
) -> List[_T]:
    """Strategy to create a sequence alternating between elements of a and b.

    inspired by https://hypothesis.readthedocs.io/en/latest/data.html#composite-strategies

    Args:
        draw (st.DrawFn): Function to draw examples.
        a (Sequence[_T]): Sequence to start with.
        b (Sequence[_T]): Secondary sequence.

    Returns:
        List[_T]: Alternating sequence.
    """
    if len(_common_elements := (set(a) & set(b))) > 0:
        raise ValueError(
            f"a and b are expected to be disjunct, but had {_common_elements} in common."
        )

    size: int = draw(st.integers(min_value=min_size, max_value=max_size))
    _result: List[_T] = []
    for i in range(size):
        if i % 2 == 0:  # first value is indexed with 0
            _result.append(draw(st.sampled_from(a)))
        else:  # i%2==1
            _result.append(draw(st.sampled_from(b)))
    return _result


@st.composite
def ops_and_tokens_strategy(
    draw: "st.DrawFn",
    min_size: int = 1,
) -> Tuple[Sequence[Operator[Token]], List[Token],]:
    """Strategy to create an alternating sequence of ops and tokens.

    inspired by https://hypothesis.readthedocs.io/en/latest/data.html#composite-strategies

    Args:
        draw (st.DrawFn): Function to draw examples.
        min_size (int, optional): Minimal length of the sequence. Defaults to 1.

    Returns:
        Tuple[Sequence[Operator[Token]], List[Token],]: Alternating sequence of Tokens and Operators.
    """
    _operator_symbols = draw(
        st.lists(
            elements=st.builds(
                cast("Callable[[str], Token]", Token),
                st.text(
                    alphabet=st.characters(blacklist_categories=BLACKLIST_CATEGORIES),
                    min_size=1,
                ),
            ),
            min_size=1,
        )
    )
    _operators: List[Operator[Token]] = []
    for _operator_symbol in _operator_symbols:
        _operators += [
            draw(
                operator_strategy_from_symbol_strategy(
                    symbol_strategy=st.just(_operator_symbol)
                )
            )
        ]

    _operator_characters: str = "".join(_operator_symbols)

    _non_operator_tokens: List[Token] = draw(
        st.lists(
            elements=st.builds(
                cast("Callable[[str], Token]", Token),
                st.text(
                    alphabet=st.characters(
                        blacklist_categories=BLACKLIST_CATEGORIES,
                        blacklist_characters=_operator_characters,
                    ),
                    min_size=1,
                ),
            ),
            min_size=1,
        )
    )

    return _operators, draw(
        st.one_of(
            alternating_strategy(_operator_symbols, _non_operator_tokens),
            alternating_strategy(_non_operator_tokens, _operator_symbols),
        )
    )

    _ops_draw: Sequence[Operator[Token]] = draw(ops_strategy)
    ops = [op for op in _ops_draw]
    assume(len(list(ops)) > 0)
    note(f"ops: {ops}")
    assert all(
        op.value == getattr(op, "symbol", op.value) for op in ops
    )  # nosec: ignore[B101]
    _operator_tokens: List[Token] = _extract_value_from_ops(list(ops))
    note(f"operator tokens: {_operator_tokens}")

    _value_tokens: List[Token] = draw(
        st.lists(
            elements=st.builds(
                cast("Callable[[str],Token]", Token),
                st.text(
                    alphabet=st.characters(
                        blacklist_characters="".join(_operator_tokens),
                        blacklist_categories=("C", "Z"),
                    ),
                    min_size=min_size,
                ),
            )
        )
    )
    note(f"tokens: {_value_tokens}")

    _all_tokens: List[Token] = _value_tokens + _operator_tokens
    note(f"all_tokens: {_all_tokens}")
    _unmerged_tokens: List[Token] = draw(
        st.lists(elements=st.sampled_from(_all_tokens), min_size=min_size)
    )
    note(f"unmerged tokens: {_unmerged_tokens}")

    def _merge_value_tokens(
        t1: Token, unprocessed_tokens: List[Token]
    ) -> List[
        Token
    ]:  # Union[Tuple[Token, Token, List[Token]], Tuple[Token, List[Token]]]:
        if len(unprocessed_tokens) == 0:
            return [t1]
        if t1 not in _operator_tokens:  # or _delim_tokens
            if unprocessed_tokens[0] not in _operator_tokens:  # or _delim_tokens
                return _merge_value_tokens(
                    Token(t1 + unprocessed_tokens[0]), unprocessed_tokens[1:]
                )
        return [t1] + _merge_value_tokens(unprocessed_tokens[0], unprocessed_tokens[1:])

    _merged_value_tokens = _merge_value_tokens(
        _unmerged_tokens[0], _unmerged_tokens[1:]
    )
    # TODO ensure Tokens and ops are alternating
    note(
        f"""
ops: {ops}
tokens: {_merged_value_tokens}
"""
    )
    return ops, _merged_value_tokens


# Strategies for building a proper AST


def operator_symbols_strategy(
    blacklist_characters: Sequence[str] = "",
) -> st.SearchStrategy[Set[Token]]:
    """Create a Strategy for a set of token optionally excluding the  blacklisted symbols.

    Args:
        blacklist_characters (Sequence[str], optional): Characters not to use in creating tokens. Defaults to "".

    Returns:
        st.SearchStrategy[Set[Token]]: Strategy for drawing a set of tokens.
    """
    return st.sets(
        elements=st.builds(
            # cast("Callable[[str], Token]", Token),
            lambda x: Token(x),
            st.text(
                alphabet=st.characters(
                    blacklist_categories=BLACKLIST_CATEGORIES,
                    blacklist_characters=blacklist_characters,
                ),
                min_size=1,
            ),
        ),
        min_size=1,
    ).filter(lambda _list: not any((a in b for a in _list for b in _list - {a})))


# strategies for preventing use of the same symbol for a postfix AND either a prefix or binary operator

unary_postfix_symbols_strategy: st.SearchStrategy[Set[Token]] = st.shared(
    operator_symbols_strategy(), key="unary_postfix"
)

non_unary_postfix_symbols_strategy: st.SearchStrategy[Set[Token]] = st.shared(
    unary_postfix_symbols_strategy.flatmap(
        lambda symbols: operator_symbols_strategy(blacklist_characters="".join(symbols))
    ),
    key="non_unary_postfix",
)


@st.composite
def non_operator_token_strategy(draw: st.DrawFn) -> Token:
    """Create an token that is not use as an operator.

    Args:
        draw (st.DrawFn): Hypothesis Draw Function.

    Returns:
        Token: Token which is not used as an operator.
    """
    unary_postfix_symbols = draw(unary_postfix_symbols_strategy)
    non_unary_postfix_symbols = draw(non_unary_postfix_symbols_strategy)
    non_operator_tokens = draw(
        st.shared(
            operator_symbols_strategy(
                blacklist_characters="".join(
                    unary_postfix_symbols | non_unary_postfix_symbols
                )
            ),
            key="non_operator_tokens",
        )
    )
    return draw(st.sampled_from(list(non_operator_tokens)))


operator_symbol_strategy: st.SearchStrategy[
    Token
] = operator_symbols_strategy().flatmap(
    lambda operator_symbols: st.sampled_from(list(operator_symbols))
)


rpn_value_token_strategy: st.SearchStrategy[List[Token]] = st.deferred(
    lambda: non_operator_token_strategy().map(lambda x: [x])
)


rpn_unary_operator_token_strategy: st.SearchStrategy[List[Token | None]] = st.one_of(
    unary_postfix_symbols_strategy.flatmap(
        lambda unary_postfix_symbols: st.sampled_from(list(unary_postfix_symbols))
    ).map(lambda unary_postfix_symbol: [None, unary_postfix_symbol]),
    non_unary_postfix_symbols_strategy.flatmap(
        lambda non_unary_postfix_symbols: st.sampled_from(
            list(non_unary_postfix_symbols)
        )
    ).map(lambda non_unary_postfix_symbol: [non_unary_postfix_symbol, None]),
)


def rpn_non_unary_operator_token_strategy(
    arg_count: int,
) -> st.SearchStrategy[List[Token | None]]:
    """Create a strategy for the value of an RPNToken depending on the argument count.

    Args:
        arg_count (int): Number of arguments expected for the RPNToken, expected to be at least 2.

    Returns:
        st.SearchStrategy[List[Token | None]]: Value for the RPNToken
    """
    return st.lists(
        elements=non_unary_postfix_symbols_strategy.flatmap(
            lambda symbols: st.sampled_from(list(symbols))
        ),  # operator_symbol_strategy,
        min_size=arg_count - 1,
        max_size=arg_count - 1,
    ).flatmap(
        lambda values: st.permutations(
            values=[v for v in values] + [None for _ in range(len(values) + 1)]
        )
    )


def rpn_operator_value_strategy(
    arg_count: int,
) -> st.SearchStrategy[List[Token | None]]:
    """Create a strategy for the value of an RPNToken depending on the argument count.

    Args:
        arg_count (int): Number of arguments expected for the RPNToken.

    Returns:
        st.SearchStrategy[List[Token | None]]: Value for the RPNToken
    """
    return (
        rpn_unary_operator_token_strategy
        if arg_count == 1
        else rpn_non_unary_operator_token_strategy(arg_count=arg_count)
    )


def rpn_token_from_arg_count_strategy(arg_count: int) -> st.SearchStrategy[RPNToken]:
    """Create a strategy for an RPNToken depending on the argument count.

    Args:
        arg_count (int): Number of arguments expected for the RPNToken.

    Returns:
        st.SearchStrategy[RPNToken]: RPNToken
    """
    if arg_count == 0:
        return rpn_value_token_strategy.map(
            lambda values: RPNToken(
                arg_count=arg_count,
                values=cast("List[Token|None]", values),
                precedence=0,
                associativity="none",
            )
        )
    elif arg_count == 1:
        return rpn_unary_operator_token_strategy.flatmap(
            lambda values: st.shared(
                st.builds(
                    lambda precedence: RPNToken(
                        arg_count=1,
                        associativity="none",
                        values=values,
                        precedence=precedence,
                    ),
                    precedence=st.integers(min_value=0),
                ),
                key=f"{values}",  # create each operator only once
            )
        )
    elif arg_count == 2:
        return rpn_non_unary_operator_token_strategy(arg_count=arg_count).flatmap(
            lambda values: st.shared(
                st.builds(
                    lambda precedence, associativity: RPNToken(
                        arg_count=arg_count,
                        values=values,
                        precedence=precedence,
                        associativity=associativity,
                    ),
                    precedence=st.integers(min_value=0),
                    associativity=st.sampled_from(["left", "right"]),
                ),
                key=f"{values}",  # create each operator only once
            )
        )
    raise


def rpn_tree_to_ops(node: RPNNode[RPNToken]) -> List[Operator[Token]]:
    """Extract operators from an RPNNode.

    Args:
        node (RPNNode): Node / Tree to extract the operators from.

    Returns:
        List[Operator[Token]]: List of Operators used in the tree.
    """
    _ret: List[Operator[Token]] = []
    if node.arg_count > 0:
        _ret.append(
            Operator[Token](
                value=[_v for _v in node.value.values if _v is not None][0],
                precedence=node.value.precedence,
                unary=node.arg_count == 1,
                unary_position=None
                if node.arg_count != 1
                else ("prefix" if node.value.values[0] is not None else "postfix"),
                associativity="none"
                if node.arg_count != 2
                else node.value.associativity,
            )
        )
        for child in node.children:
            _ret.extend(rpn_tree_to_ops(child))

    return _ret


@st.composite
def rpn_node_value_node_strategy(draw: st.DrawFn) -> RPNNode[RPNToken]:
    """Create an RPNNode without children.

    Args:
        draw (st.DrawFn): Hypothesis Draw Function.

    Returns:
        RPNNode: RPNNode without children.
    """
    token = draw(rpn_token_from_arg_count_strategy(0))
    children: List[RPNNode[RPNToken]] = []
    return RPNNode[RPNToken](
        arg_count=token.arg_count,
        value=token,
        children=children,
    )


@st.composite
def rpn_operator_node_from_value_node_strategy(
    draw: st.DrawFn,
    elements: st.SearchStrategy[RPNNode[RPNToken]],
) -> RPNNode[RPNToken]:
    """Create an RPNNode with children.

    Args:
        draw (st.DrawFn): Hypothesis Draw Function.
        elements (st.SearchStrategy[RPNNode]): Strategy to draw children from.

    Returns:
        RPNNode: RPNNode with children.
    """
    children = draw(st.lists(elements=elements, min_size=1, max_size=2))
    token = draw(rpn_token_from_arg_count_strategy(len(children)))
    _ops: List[Operator[Token]] = []
    for child in children:
        _ops.extend(rpn_tree_to_ops(child))
    try:
        sanity_check_operators(_ops)
    except ValueError:
        assume(False)

    return RPNNode(
        arg_count=len(children),
        value=token,
        children=children,
    )


rpn_node_strategy_recursive: st.SearchStrategy[RPNNode[RPNToken]] = st.recursive(
    rpn_node_value_node_strategy(),
    rpn_operator_node_from_value_node_strategy,
    max_leaves=2,
)


def _hypothesis_setup_hook() -> None:  # pyright: ignore[reportUnusedFunction]
    logger.debug("Registering strategies")

    non_empty_string_strategy: st.SearchStrategy[str] = st.text(
        st.characters(blacklist_categories=("C", "Z")), min_size=1
    )
    st.register_type_strategy(
        Token,
        st.builds(Token, non_empty_string_strategy),
    )

    st.register_type_strategy(
        Operator[Token], operator_from_symbol_type_strategy(Token)
    )
    st.register_type_strategy(
        OpeningDelim,
        st.builds(OpeningDelim, object=non_empty_string_strategy),
    )
    st.register_type_strategy(
        ClosingDelim,
        st.builds(ClosingDelim, object=non_empty_string_strategy),
    )
    st.register_type_strategy(DelimPair, delim_pair_strategy)
